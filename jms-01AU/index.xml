<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors>
      <fr:author>
        <fr:link href="/jonmsterling/" title="Jon Sterling" uri="https://www.jonmsterling.com/jonmsterling/" display-uri="jonmsterling" type="local">Jon Sterling</fr:link>
      </fr:author>
    </fr:authors>
    <fr:date>
      <fr:year>2025</fr:year>
      <fr:month>4</fr:month>
      <fr:day>25</fr:day>
    </fr:date>
    <fr:uri>https://www.jonmsterling.com/jms-01AU/</fr:uri>
    <fr:display-uri>jms-01AU</fr:display-uri>
    <fr:route>/jms-01AU/</fr:route>
    <fr:title text="We have AI at home… › Arise, symbolic AI!"><fr:link href="/jms-01AS/" title="We have AI at home…" uri="https://www.jonmsterling.com/jms-01AS/" display-uri="jms-01AS" type="local">We have AI at home…</fr:link> › Arise, symbolic AI!</fr:title>
  </fr:frontmatter>
  <fr:mainmatter>
    <html:p>There is a lot of discussion lately of the impact that some current machine learning techniques, marketed as “Artificial Intelligence”, can have on formalisation of mathematics in proof assistants. Some of the <fr:link href="https://www.math.ucla.edu/~tao/" type="external">most esteemed</fr:link> members of the mathematical community have gone <html:em>all in</html:em> on this trend <html:span style="font-size: smaller">(is it a requirement of scientific fame and esteem that you begin to cause trouble in areas of research that you know nothing about?)</html:span>, but I think that evaluating LLMs on Olympiad questions is really missing the point of what computers can do to assist mathematicians. Olympiads are a good fit for LLMs, because kids who participate in Olympiads are behaving much more like LLMs than human mathematicians—the mathematics Olympiad is the ultimate feat of pattern-recognition without understanding, and they are certainly a good fit for the <html:em>Might Makes Right</html:em> approach being taken within AI today.</html:p>
    <html:p>Agda (and Lean and Rocq and Isabelle) are “Artificial Intelligences” in the most progressive sense—they augment the limited context that a human can store in their mind at once, and are nimble tools for working mathematicians to check and verify their ideas, and (most importantly) they do not proceed by creating a fetish of illusion and misdirection that deceives the public. Their capabilities are limited, but well-circumscribed. I think often about how important it is to know in a definite sense what a tool can and cannot do, and I increasingly think that this is actually part of what makes something a <html:em>tool</html:em>. Some of my colleagues have compared LLMs to calculators, in order to make the case that we should get ready for them to be used as everyday tools; but LLMs are not simply tools in the sense that a calculator is a tool.</html:p>
  </fr:mainmatter>
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>
                <fr:link href="/jonmsterling/" title="Jon Sterling" uri="https://www.jonmsterling.com/jonmsterling/" display-uri="jonmsterling" type="local">Jon Sterling</fr:link>
              </fr:author>
            </fr:authors>
            <fr:date>
              <fr:year>2025</fr:year>
              <fr:month>4</fr:month>
              <fr:day>25</fr:day>
            </fr:date>
            <fr:uri>https://www.jonmsterling.com/jms-01AS/</fr:uri>
            <fr:display-uri>jms-01AS</fr:display-uri>
            <fr:route>/jms-01AS/</fr:route>
            <fr:title text="We have AI at home…">We have AI at home…</fr:title>
          </fr:frontmatter>
          <fr:mainmatter>
            <html:p>On Tuesday, I travelled by train to Sheffield to take part in the <fr:link href="/yamcats-37/" title="Yorkshire and Midlands Category Theory Seminar 37" uri="https://www.jonmsterling.com/yamcats-37/" display-uri="yamcats-37" type="local">Yorkshire and Midlands Category Theory Seminar 37</fr:link> meeting, where I would be <fr:link href="/sterling-2025-yamcats-37/" title="When is the partial map classifier a Sierpiński cone?" uri="https://www.jonmsterling.com/sterling-2025-yamcats-37/" display-uri="sterling-2025-yamcats-37" type="local">speaking</fr:link> about my <fr:link href="/pugh-sterling-2025/" title="When is the partial map classifier a Sierpiński cone?" uri="https://www.jonmsterling.com/pugh-sterling-2025/" display-uri="pugh-sterling-2025" type="local">paper</fr:link> that compares partial map classifiers with Sierpiński cones in synthetic (domain/category) theory, which I <fr:link href="/jms-01A6/" title="Weeknotes 2025-W15 › Two papers to appear in LICS ’25 › With Leoni Pugh: When is the partial map classifier a Sierpiński cone?" uri="https://www.jonmsterling.com/jms-01A6/" display-uri="jms-01A6" type="local">summarised previously</fr:link>.</html:p>
            <fr:tree show-metadata="false">
              <fr:frontmatter>
                <fr:authors>
                  <fr:author>
                    <fr:link href="/jonmsterling/" title="Jon Sterling" uri="https://www.jonmsterling.com/jonmsterling/" display-uri="jonmsterling" type="local">Jon Sterling</fr:link>
                  </fr:author>
                </fr:authors>
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>4</fr:month>
                  <fr:day>25</fr:day>
                </fr:date>
                <fr:uri>https://www.jonmsterling.com/jms-01AT/</fr:uri>
                <fr:display-uri>jms-01AT</fr:display-uri>
                <fr:route>/jms-01AT/</fr:route>
                <fr:title text="A pleasant surprise">A pleasant surprise</fr:title>
              </fr:frontmatter>
              <fr:mainmatter>
                <html:p>I was preparing for my chalk talk when I realised that I could not remember the details of the proof of the main result and they couldn’t really be reconstructed from the abbreviated proof in the paper.</html:p>
                <html:p>Luckily, I had actually formalised this result in Agda! I did not mention my formalisation in the paper because I do not think of formalisations as scientific contributions except in certain cases (that is a conversation for another day). But I did indeed formalise it because the proof was subtle enough that I needed computerised assistance back when I proved it the first time. The result I obtained was frustratingly weak, and seemed to require some annoying side conditions in order to go through; the formalisation helped me be certain that these side conditions were in fact sufficient.</html:p>
                <html:p>Anyway, I was messing around with the code and what I realised was that I had missed a trick back then: <html:strong>one of the side conditions was actually unnecessary</html:strong>, and it seems kind of likely that the other one is unnecessary too. I am certain I would not have noticed this if I hadn't had the proof assistant, which made it easy for me to try something out and see if it worked. I should have time to update the paper to claim the strong result prior to the <fr:link href="/lics-2025/" title="LICS ’25: 40th Annual ACM/IEEE Symposium on Logic in Computer Science" uri="https://www.jonmsterling.com/lics-2025/" display-uri="lics-2025" type="local">LICS</fr:link> camera-ready deadline next month.</html:p>
              </fr:mainmatter>
            </fr:tree>
            <fr:tree show-metadata="false">
              <fr:frontmatter>
                <fr:authors>
                  <fr:author>
                    <fr:link href="/jonmsterling/" title="Jon Sterling" uri="https://www.jonmsterling.com/jonmsterling/" display-uri="jonmsterling" type="local">Jon Sterling</fr:link>
                  </fr:author>
                </fr:authors>
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>4</fr:month>
                  <fr:day>25</fr:day>
                </fr:date>
                <fr:uri>https://www.jonmsterling.com/jms-01AU/</fr:uri>
                <fr:display-uri>jms-01AU</fr:display-uri>
                <fr:route>/jms-01AU/</fr:route>
                <fr:title text="Arise, symbolic AI!">Arise, symbolic AI!</fr:title>
              </fr:frontmatter>
              <fr:mainmatter>
                <html:p>There is a lot of discussion lately of the impact that some current machine learning techniques, marketed as “Artificial Intelligence”, can have on formalisation of mathematics in proof assistants. Some of the <fr:link href="https://www.math.ucla.edu/~tao/" type="external">most esteemed</fr:link> members of the mathematical community have gone <html:em>all in</html:em> on this trend <html:span style="font-size: smaller">(is it a requirement of scientific fame and esteem that you begin to cause trouble in areas of research that you know nothing about?)</html:span>, but I think that evaluating LLMs on Olympiad questions is really missing the point of what computers can do to assist mathematicians. Olympiads are a good fit for LLMs, because kids who participate in Olympiads are behaving much more like LLMs than human mathematicians—the mathematics Olympiad is the ultimate feat of pattern-recognition without understanding, and they are certainly a good fit for the <html:em>Might Makes Right</html:em> approach being taken within AI today.</html:p>
                <html:p>Agda (and Lean and Rocq and Isabelle) are “Artificial Intelligences” in the most progressive sense—they augment the limited context that a human can store in their mind at once, and are nimble tools for working mathematicians to check and verify their ideas, and (most importantly) they do not proceed by creating a fetish of illusion and misdirection that deceives the public. Their capabilities are limited, but well-circumscribed. I think often about how important it is to know in a definite sense what a tool can and cannot do, and I increasingly think that this is actually part of what makes something a <html:em>tool</html:em>. Some of my colleagues have compared LLMs to calculators, in order to make the case that we should get ready for them to be used as everyday tools; but LLMs are not simply tools in the sense that a calculator is a tool.</html:p>
              </fr:mainmatter>
            </fr:tree>
          </fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
